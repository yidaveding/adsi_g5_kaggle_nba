{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 22)\n",
      "(3799, 21)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/jovyan/work\")\n",
    "\n",
    "train_data = pd.read_csv('../data/raw/train.csv')\n",
    "test_data = pd.read_csv('../data/raw/test.csv')\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 22)\n",
      "(6400, 19)\n",
      "(1600, 19)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train_data_x = train_data.copy()\n",
    "train_data_x = train_data_x.drop(['Id_old', 'Id'], axis=1)\n",
    "train_data_target = train_data_x.pop('TARGET_5Yrs')\n",
    "\n",
    "test_data_x = test_data.drop(['Id_old', 'Id'], axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_train_scaled = pd.DataFrame(scaler.fit_transform(train_data_x), columns=train_data_x.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train_scaled, train_data_target, test_size=0.2, random_state=42)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Cross Validation to evaluate multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import isnan\n",
    "from numpy import asarray\n",
    "from numpy import polyfit\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset\n",
    "def get_dataset(n_samples=100):\n",
    "    X, y = make_classification(n_samples=n_samples, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "    return X, y\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models_p1():\n",
    "    models = list()\n",
    "    models.append(GaussianNB())\n",
    "    models.append(AdaBoostClassifier())\n",
    "    models.append(BaggingClassifier())\n",
    "    models.append(RandomForestClassifier())\n",
    "    models.append(ExtraTreesClassifier())\n",
    "    models.append(GradientBoostingClassifier())\n",
    "    models.append(LinearDiscriminantAnalysis())\n",
    "    models.append(QuadraticDiscriminantAnalysis())\n",
    "    return models\n",
    "\n",
    "def get_models_p2():\n",
    "    models = list()\n",
    "    models.append(LogisticRegression())\n",
    "    models.append(RidgeClassifier())\n",
    "    models.append(SGDClassifier())\n",
    "    models.append(PassiveAggressiveClassifier())\n",
    "    models.append(KNeighborsClassifier())\n",
    "    models.append(DecisionTreeClassifier())\n",
    "    models.append(ExtraTreeClassifier())\n",
    "    models.append(LinearSVC())\n",
    "    models.append(SVC())\n",
    "    return models\n",
    " \n",
    "# evaluate the model using a given test condition\n",
    "def evaluate_model(cv, model, X_train, y_train):\n",
    "    # get the dataset\n",
    "    X, y = X_train, y_train\n",
    "    # evaluate the model\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # return scores\n",
    "    return mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define test conditions\n",
    "ideal_cv = LeaveOneOut()\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# get the list of models to consider\n",
    "models1 = get_models_p1()\n",
    "# collect results\n",
    "ideal_results, cv_results = list(), list()\n",
    "# evaluate each model\n",
    "for model in models1:\n",
    "    # evaluate model using each test condition\n",
    "    cv_mean = evaluate_model(cv, model, X_train, y_train)\n",
    "    ideal_mean = evaluate_model(ideal_cv, model, X_train, y_train)\n",
    "    # check for invalid results\n",
    "    if isnan(cv_mean) or isnan(ideal_mean):\n",
    "        continue\n",
    "    # store results\n",
    "    cv_results.append(cv_mean)\n",
    "    ideal_results.append(ideal_mean)\n",
    "    # summarize progress\n",
    "    print('>%s: ideal=%.3f, cv=%.3f' % (type(model).__name__, ideal_mean, cv_mean))\n",
    "# calculate the correlation between each test condition\n",
    "corr, _ = pearsonr(cv_results, ideal_results)\n",
    "print('Correlation: %.3f' % corr)\n",
    "# scatter plot of results\n",
    "pyplot.scatter(cv_results, ideal_results)\n",
    "# plot the line of best fit\n",
    "coeff, bias = polyfit(cv_results, ideal_results, 1)\n",
    "line = coeff * asarray(cv_results) + bias\n",
    "pyplot.plot(cv_results, line, color='r')\n",
    "# label the plot\n",
    "pyplot.title('10-fold CV vs LOOCV Mean Accuracy')\n",
    "pyplot.xlabel('Mean Accuracy (10-fold CV)')\n",
    "pyplot.ylabel('Mean Accuracy (LOOCV)')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define test conditions\n",
    "ideal_cv = LeaveOneOut()\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# get the list of models to consider\n",
    "models1 = get_models_p1()\n",
    "# collect results\n",
    "ideal_results, cv_results = list(), list()\n",
    "# evaluate each model\n",
    "for model in models1:\n",
    "    # evaluate model using each test condition\n",
    "    cv_mean = evaluate_model(cv, model)\n",
    "    ideal_mean = evaluate_model(ideal_cv, model)\n",
    "    # check for invalid results\n",
    "    if isnan(cv_mean) or isnan(ideal_mean):\n",
    "        continue\n",
    "    # store results\n",
    "    cv_results.append(cv_mean)\n",
    "    ideal_results.append(ideal_mean)\n",
    "    # summarize progress\n",
    "    print('>%s: ideal=%.3f, cv=%.3f' % (type(model).__name__, ideal_mean, cv_mean))\n",
    "# calculate the correlation between each test condition\n",
    "corr, _ = pearsonr(cv_results, ideal_results)\n",
    "print('Correlation: %.3f' % corr)\n",
    "# scatter plot of results\n",
    "pyplot.scatter(cv_results, ideal_results)\n",
    "# plot the line of best fit\n",
    "coeff, bias = polyfit(cv_results, ideal_results, 1)\n",
    "line = coeff * asarray(cv_results) + bias\n",
    "pyplot.plot(cv_results, line, color='r')\n",
    "# label the plot\n",
    "pyplot.title('10-fold CV vs LOOCV Mean Accuracy')\n",
    "pyplot.xlabel('Mean Accuracy (10-fold CV)')\n",
    "pyplot.ylabel('Mean Accuracy (LOOCV)')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
